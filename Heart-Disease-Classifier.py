import sys
import numpy as np
from numpy import random as rnd
from matplotlib import pyplot as plt
import csv

def train(n):
    """
    A function that trains a model to classify provided data into (has heart desease, or doesn't have heart disease)
    based on provided train data (heart_train.csv).

    :param n: polynomial order, where 1 means linear, 2 means 2nd order.
    """
    # ---------------------- Read input ---------------------- #
    x = np.transpose(np.loadtxt("heart_train.csv", delimiter=',', skiprows=1, usecols=range(13)))
    y = np.loadtxt("heart_train.csv", delimiter=',', skiprows=1, usecols=-1)
    # ------------------- Feature Scaling -------------------- #
    s_factor = np.amax(x, axis=1)
    x = x / s_factor[:, None]

    num_of_examples = x.shape[1]

    # --------- Manipulate input data for processing --------- #
    """
        trainX = [1 , 1,  1  ... ] <--- To be multiplied by Theta0
                 [x1, x2, x3 ... ] <--- Feature 1, multiplies by Theta1
                 [v1, v2, v3 ... ] <--- Feature 2, multiplied by Theta2
                 ... etc

        trainY = [Y1, Y2, Y3 ... ]
    """
    trainY = y
    trainX = np.vstack([np.ones(num_of_examples), x])

    # Based on input, choose whether to go with linear model (first order), or second order nonlinear model.
    # ----------------- default output file ----------------- #
    output_thetas = "linear_thetas"
    if n == 1:  # linear (power 1), do nothing because this is the default
        pass
    elif n == 2:  # power 2
        trainX = np.vstack([trainX, np.square(x)])
        output_thetas = "poly_order2_thetas"
    num_of_features = trainX.shape[0]

    # ------------ Thetas random start point ------------ #
    rnd.seed(100)  # Fixed for comparing different models with different lr
    thetas = rnd.random(num_of_features)
    # ----------------- Learning rate ------------------- #
    lr = 0.75
    # --------------- Initialize variables -------------- #
    loss = list()
    hyp = None

    # -------------------- Main Loop -------------------- #
    for i in range(300000):
        """ hypothesis hyp = [h1 , h2,  h3  ... ]. (This is the guess generated by current value of theta)"""
        hyp = 1 / (1 + np.exp(-np.dot(thetas, trainX)))

        """ Update theta"""
        # Note: The vstack below works only for single row vectors. so if hyp was [[2,3,3],[1,1,1]] then it wont work
        grad = np.dot(trainX, np.vstack(hyp - trainY) / num_of_examples)
        thetas = thetas - (lr * np.hstack(grad))

        """Calculate loss"""
        loss.append(-np.sum(np.log(hyp) * trainY + np.log(1 - hyp) * (1 - trainY)) / num_of_examples)
        relative_loss = abs((loss[i] - loss[i - 1]) / loss[i] * 100)
        if relative_loss <= 0.0001 and i != 0:
            print("Stopped at iteration: " + str(i))
            break

    # --------------------- output area ---------------------- #
    # Console output
    print("loss is: " + str(loss[-1]))
    criteria_check(hyp, y, n, output_to_file=False)

    # Save thetas for test phase
    np.save(output_thetas, thetas)  # Save thetas for the test phase.

    # Loss Plot
    plt.plot(loss)
    plt.show()


def test(n):
    """
    A function that tests the trained model, based on provided test data set (heart_test.csv)

    :param n: polynomial order, where 1 means linear, 2 means 2nd order.
    """
    # ----------------- Reading Input ---------------- #
    x = np.transpose(np.loadtxt("heart_train.csv", delimiter=',', skiprows=1, usecols=range(13)))
    y = np.loadtxt("heart_train.csv", delimiter=',', skiprows=1, usecols=-1)
    # ------------------- Feature Scaling -------------------- #
    s_factor = np.amax(x, axis=1)
    x = x / s_factor[:, None]
    (x_m, x_n) = x.shape

    # ---------------------- Test ---------------------- #
    print("\n\n#==================== Testing ====================#")
    train_thetas = None
    testX = None
    testY = y
    if n == 1:
        train_thetas = np.load("linear_thetas.npy")
        testX = np.vstack([np.ones(x_n), x])
    elif n == 2:
        train_thetas = np.load("poly_order2_thetas.npy")
        testX = np.vstack([np.ones(x_n), x, np.square(x)])

    hyp = 1 / (1 + np.exp(-np.dot(train_thetas, testX)))
    test_loss = -np.sum(np.log(hyp) * testY + np.log(1 - hyp) * (1 - testY)) / x_n
    print("Test Loss is: " + str(test_loss))

    criteria_check(hyp, y, n, output_to_file=True)


def criteria_check(hyp, y, n, output_to_file):
    """
    A function that is called upon the end of training/during test phase, to check the model performance, according to
    some criteria: accuracy, precision, recall, F1-score.

    :param hyp:                 The hypothesis equation of the trained model, or in other words, this is the predicted
                                output for each input.
    :param y:                   The actual output that corresponds to each input.
    :param output_to_file:      boolean. If true, the results will be written to csv file.
    :return:                    None.
    """
    # ----------------- initialize variables ----------------- #
    true_pos = 0
    false_pos = 0
    true_neg = 0
    false_neg = 0
    prediction = list()
    threshold = 0.5
    # ----------------- calc positives and negatives ----------------- #
    for i in range(len(hyp)):
        if hyp[i] > threshold:
            prediction.append(1)
            print("The predicted class is: ", 1, ", the actual class is: ", y[i], ",   ", y[i] == 1)
            if y[i] == 1:
                true_pos += 1
            else:
                false_pos += 1
        else:
            prediction.append(0)
            print("The predicted class is: ", 0, ", the actual class is: ", y[i], ",   ", y[i] == 0)
            if y[i] == 0:
                true_neg += 1
            else:
                false_neg += 1

    # ----------------- calc and print results ----------------- #
    print("Number of correct guesses is: ", true_pos + true_neg)
    accuracy = (true_pos + true_neg) / len(y) * 100
    precision = true_pos / (true_pos + false_pos) * 100
    recall = true_pos / (true_pos + false_neg) * 100
    f1_score = 2 * recall * precision / (recall + precision)
    print("Accuracy: ", accuracy, "\nprecision: ", precision, "\nrecall: ", recall, "\nF1_score: ", f1_score)

    # ----------------- Output to csv file ----------------- #
    if output_to_file:
        if n ==1:
            output_file_name = "Output_Linear.csv"
        else:
            output_file_name = "Output_poly_ord2.csv"
        yEQp = list(y == prediction)
        y = y.tolist()
        with open(output_file_name, 'w', newline='') as file:
            writer = csv.writer(file)
            y.insert(0, "Truth")
            prediction.insert(0, "Prediction")
            yEQp.insert(0, "Correct?")
            writer.writerows([y, prediction, yEQp])
            writer.writerows([['--------', '--------', '--------', '--------', '--------'],
                              ["True pos ", "True neg", "False pos", "False neg"],
                              [true_pos, true_neg, false_pos, false_neg],
                              ['--------', '--------', '--------', '--------', '--------'],
                              ["Accuracy", "precision", "Recall", "F1-score"],
                              [accuracy, precision, recall, f1_score]])


if __name__ == "__main__":
    if len(sys.argv) == 1:
        print("not enough arguments.\n"
              "Use the following arguments in command line:\n"
              "\tT1: Train a linear model\n"
              "\tT2: Train a polynomial model of order 2\n"
              "\tV: validate(test) the trained models")
        exit()

    if sys.argv[1].upper() == "T1":
        train(1)
    elif sys.argv[1].upper() == "T2":
        train(2)
    elif sys.argv[1].upper() == "V1":
        test(1)
    elif sys.argv[1].upper() == "V2":
        test(2)
    else:
        print("wrong command line argument.")
        exit()
